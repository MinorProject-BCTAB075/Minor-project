{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213602d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b6b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#modelI=keras.models.load_model('modelnew.keras')\n",
    "modelI=keras.models.load_model('saved_model/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b62aaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_symbols = {\n",
    "    10:'-', 11:'+', 12:'*', 13:'=', 14:'a', 15:'b', 16:'<', 17:'>', 18:'/',19:'√', 20:'(',21:')'\n",
    "}\n",
    "for i in range(0,10):\n",
    "    labels_symbols[i] = chr(48+i)\n",
    "\n",
    "symbols_folder = {'*':'times','/':'','<':'','>':'','√':'','(':'',')':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e81b4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_parts_from_image(path, display_img = False ):\n",
    "    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    if display_img:\n",
    "        print(path)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(~img,cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    train_data=[]\n",
    "    if img is not None:\n",
    "        img=~img\n",
    "        ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "        ctrs,ret=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt=sorted(ctrs,key=lambda ctr:cv2.boundingRect(ctr)[0])\n",
    "        w=int(28)\n",
    "        h=int(28)\n",
    "        rects=[]\n",
    "        for c in cnt:\n",
    "            x,y,w,h=cv2.boundingRect(c)\n",
    "            rect=[x,y,w,h]\n",
    "            rects.append(rect)\n",
    "    #     print(\"rects\", rects)\n",
    "        bool_rect=[]\n",
    "        for r in rects:\n",
    "            l=[]\n",
    "            for rec in rects:\n",
    "                flag=0\n",
    "                if rec!=r:\n",
    "                    if r[0]<(rec[0]+rec[2]+10) and rec[0]<(r[0]+r[2]+10) and r[1]<(rec[1]+rec[3]+10) and rec[1]<(r[1]+r[3]+10):\n",
    "                        flag=1\n",
    "                    l.append(flag)\n",
    "                if rec==r:\n",
    "                    l.append(0)\n",
    "            bool_rect.append(l)\n",
    "    #     print(\"bools\",bool_rect)\n",
    "        dump_rect=[]\n",
    "        for i in range(0,len(cnt)):\n",
    "            for j in range(0,len(cnt)):\n",
    "                if bool_rect[i][j]==1:\n",
    "                    area1=rects[i][2]*rects[i][3]\n",
    "                    area2=rects[j][2]*rects[j][3]\n",
    "                    if(area1==min(area1,area2)):\n",
    "                        dump_rect.append(rects[i])\n",
    "    #     print(\"dump_rects\",dump_rect)\n",
    "        final_rect=[i for i in rects if i not in dump_rect]\n",
    "    #     print(\"Final_rects\",final_rect)\n",
    "        for r in final_rect:\n",
    "            x=r[0]\n",
    "            y=r[1]\n",
    "            w=r[2]\n",
    "            h=r[3]\n",
    "            im_crop=thresh[y:y+h+10,x:x+w+10]\n",
    "            im_resize=cv2.resize(im_crop,(28,28))\n",
    "    #         cv2.imshow(\"work\",im_resize)\n",
    "            train_data.append(im_resize)\n",
    "        \n",
    "        return train_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7160c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "def recognise_parts(imgs, symb_imgs_store=None):\n",
    "    s=\"\"\n",
    "    for i in range(len(imgs)):\n",
    "        if symb_imgs_store is not None:\n",
    "            symb_imgs_store.append(imgs[i])\n",
    "        imgs[i]=np.array(imgs[i])\n",
    "        imgs[i]=imgs[i].reshape(1,28,28,1)\n",
    "    #     result=modelI.predictclasses(train_data[i])\n",
    "        result=np.argmax(modelI.predict(imgs[i]), axis=1)\n",
    "        s+= labels_symbols[result[0]]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ac09c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(img_path,display_parts=False,symb_imgs_store=None):\n",
    "    train_data = get_parts_from_image(img_path, display_img = False)\n",
    "    if display_parts:\n",
    "        print(f\"number of parts = {len(train_data)}\")\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,2)\n",
    "    n_per_line = 10\n",
    "    if display_parts:\n",
    "        for i,part in enumerate(train_data):\n",
    "            if i%n_per_line == 0 :\n",
    "                fig, ax = plt.subplots(ncols = n_per_line)\n",
    "                for x in ax: x.axis('off')\n",
    "            ax[i%n_per_line].imshow(part, cmap='gray')\n",
    "            #ax.plot()\n",
    "        plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"] \n",
    "        plt.show()\n",
    "\n",
    "    detected_exp = recognise_parts(train_data, symb_imgs_store = symb_imgs_store)\n",
    "\n",
    "    if display_parts: \n",
    "        print(f\"Detected Expression : {detected_exp}\")\n",
    "    \n",
    "    return detected_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecbd6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyscreenshot as IG\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "def take_screenshot(winfo=None):\n",
    "    imageName = \"hellohi.jpg\"\n",
    "    screenshot = IG.grab()\n",
    "    if winfo is not None:\n",
    "        screenshot=screenshot.crop(winfo)\n",
    "    screenshot_npArray = np.array(screenshot.getdata())\n",
    "    filepath = f\"./test_drawn_images/{imageName}\"\n",
    "    screenshot.save(filepath)\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6201e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from PIL import Image\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e70e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "./test_images_error_to_train/1\n"
     ]
    }
   ],
   "source": [
    "error_test_store = './test_images_error_to_train'\n",
    "\n",
    "class paintApp:\n",
    "    \n",
    "    left_bt_up, right_bt_up = None, None\n",
    "    x_pos, y_pos = None, None\n",
    "    x1, y1, x2, y2 = None, None, None, None\n",
    "    \n",
    "    result_box = None\n",
    "    store_for_train_box = None\n",
    "    \n",
    "    root = None\n",
    "    #button\n",
    "    \n",
    "    def __init__(self,root):\n",
    "        \n",
    "        self.error_imgs_train_cache = []\n",
    "        \n",
    "        self.root = root\n",
    "        self.cached_img_path=None\n",
    "        \n",
    "        drawing_area = Canvas(root, background='white')\n",
    "        self.drawing_area = drawing_area\n",
    "        #drawing_area.pack()\n",
    "        drawing_area.grid(sticky=(W,E))\n",
    "        drawing_area.columnconfigure(0,weight=1)\n",
    "        \n",
    "        drawing_area.bind(\"<Motion>\", self.motion)\n",
    "        drawing_area.bind(\"<ButtonPress-1>\", self.left_bt_down)\n",
    "        drawing_area.bind(\"<ButtonRelease-1>\", self.left_bt_up)\n",
    "        \n",
    "        \n",
    "        buttons_area = Canvas(root,background=\"red\")\n",
    "        #buttons_area.pack()\n",
    "        buttons_area.grid(row=1,sticky=(W,E))\n",
    "        buttons_area.columnconfigure(tuple(range(5)), weight=1)\n",
    "        buttons_area.columnconfigure(tuple(range(2)), weight=4)\n",
    "        \n",
    "        self.result_box = Text(buttons_area, bg='black', fg='white',\n",
    "                               height=0.5, width=10, font=('Helvatical bold',20), \n",
    "                               padx = 10, pady=10)\n",
    "        #self.result_box['state'] = 'disabled'\n",
    "        self.result_box.tag_configure(\"center\", justify='center')\n",
    "        self.result_box.tag_add(\"center\", 1.0, \"end\")\n",
    "        self.result_box.grid(row=0,column=1)#pack()\n",
    "        \n",
    "        submit_btn = Button(buttons_area, text=\"Predict\", command = self.predict)\n",
    "        submit_btn.grid(row=0,column=2)#pack()\n",
    "        \n",
    "        clear_btn = Button(buttons_area, text=\"clear\", command = self.clear)\n",
    "        clear_btn.grid(row=0,column=3)#pack()\n",
    "        \n",
    "        store_for_train_btn = Button(buttons_area, text=\"store for training\", command = self.store_for_train)\n",
    "        store_for_train_btn.grid(row=1,column=2)#pack()\n",
    "        \n",
    "        self.store_for_train_box = Text(buttons_area, bg='black', fg='white',\n",
    "                               height=0.5, width=10, font=('Helvatical bold',20), \n",
    "                               highlightthickness = 0, borderwidth=2, \n",
    "                                insertwidth=1, insertbackground='green',\n",
    "                               padx = 10, pady=10)\n",
    "        self.store_for_train_box.tag_configure(\"center\", justify='center')\n",
    "        self.store_for_train_box.tag_add(\"center\", 1.0, \"end\")\n",
    "        self.store_for_train_box.grid(row=1,column=1)#pack()\n",
    "        \n",
    "        \n",
    "    def left_bt_down(self, event=None):\n",
    "        self.left_bt_up = False\n",
    "        self.x1, self.y1 = event.x, event.y\n",
    "    \n",
    "    def left_bt_up(self, event=None):\n",
    "        self.left_bt_up = True\n",
    "        self.x2, self.y2 = event.x, event.y\n",
    "        self.x_pos, self.y_pos = None, None\n",
    "    \n",
    "    def motion(self, event=None):\n",
    "        self.pencil_draw(event)\n",
    "        \n",
    "    def pencil_draw(self, event=None):\n",
    "        if self.left_bt_up == False:\n",
    "            if None not in (self.x_pos, self.y_pos):\n",
    "                self.drawing_area.create_line(self.x_pos,self.y_pos,event.x,event.y,\n",
    "                                              width=3,fill='black',capstyle=ROUND,smooth=True)\n",
    "                #event.widget.create_line(self.x_pos, self.y_pos, event.x, event.y, smooth = True, width=10)\n",
    "            self.x_pos, self.y_pos = event.x, event.y\n",
    "    \n",
    "    def clear(self):\n",
    "        self.cached_img_path = None\n",
    "        self.drawing_area.delete('all')\n",
    "        self.result_box.delete('1.0',END)\n",
    "    \n",
    "    def predict(self, event=None):\n",
    "        \n",
    "        #this part is for taking the screenshot and cropping the image to canvas only\n",
    "        #needed to multiply by factors due to, i think, resolution mismatch\n",
    "        left,top = self.drawing_area.winfo_rootx(),\\\n",
    "                    self.drawing_area.winfo_rooty()#+self.drawing_area.winfo_y()\n",
    "        width,height = self.drawing_area.winfo_width(),self.drawing_area.winfo_height()\n",
    "        res_fac = 1.2508,1.2531\n",
    "        delta = 3,3\n",
    "        delta_sz = 2,2\n",
    "        left,top, width, height = (left+delta[0])*res_fac[0], (top+delta[1])*res_fac[1], \\\n",
    "                                    (width-delta[0]-delta_sz[0])*res_fac[0], (height-delta[1]-delta_sz[1])*res_fac[1]\n",
    "        img_path = take_screenshot((left, top, left+width, top+height))\n",
    "        \n",
    "#         img=cv2.imread(img_path,cv2.IMREAD_UNCHANGED)\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "        self.cached_img_path=img_path\n",
    "        self.error_imgs_train_cache = []\n",
    "        ans = predict_image(img_path, symb_imgs_store = self.error_imgs_train_cache)\n",
    "        self.result_box.delete('1.0',END)\n",
    "        self.result_box.insert('1.0',str(ans),\"center\")\n",
    "        \n",
    "    def store_for_train(self,event=None):\n",
    "        #copy image to folder\n",
    "            #create if not exists appropriate sub_folder and filename\n",
    "        correct_expr = self.store_for_train_box.get('1.0',END)\n",
    "        correct_expr = correct_expr.strip()\n",
    "        print(len(correct_expr), len(self.error_imgs_train_cache))\n",
    "        for i in range(len(correct_expr)):\n",
    "            c = correct_expr[i]\n",
    "            img = Image.fromarray(self.error_imgs_train_cache[i])\n",
    "            path = error_test_store + '/'+ c if not c in symbols_folder else symbols_folder[c]\n",
    "            print(path)\n",
    "            if not os.path.isdir(path):\n",
    "                os.mkdir(path)\n",
    "            \n",
    "            img_path = path + \"/\"+time.strftime(\"%Y%m%d-%H%M%S\")+ '.jpg'\n",
    "            img.save(img_path)\n",
    "            \n",
    "        pass\n",
    "        \n",
    "        \n",
    "root = Tk()\n",
    "paintApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884e19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
